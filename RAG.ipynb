{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in h:\\anaconda\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in h:\\anaconda\\lib\\site-packages (from wikipedia) (2.25.1)\n",
      "Requirement already satisfied: beautifulsoup4 in h:\\anaconda\\lib\\site-packages (from wikipedia) (4.9.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in h:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in h:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in h:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in h:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
      "Requirement already satisfied: soupsieve>1.2 in h:\\anaconda\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'You are a highly capable AI assistant specialized in automating requirement analysis.  \\nYour task is to extract and analyze requirements for an AI-powered Study Companion Discord Bot by retrieving relevant data from Wikipedia and generating structured, insightful answers.\\n\\nPlease ensure your answers clearly outline key features, technical specifications, and best practices based on the retrieved data.\\n\\nAnalyze the following requirement: What are the key requirements for an AI-powered Study Companion Discord Bot?\\n\\n**Comparison of user features of messaging platforms**: Comparison of user features of messaging platforms refers to a comparison of all the various user features of various electronic instant messaging platforms. This includes a wide variety of resources; it includes standalone apps, platforms within websites, computer software, and various internal functions available on specific devices, such as iMessage for iPhones.\\nThis entry includes only the features and functions that shape the user experience for such apps. A comparison of the underlying system components, programming aspects, and other internal technical information, is outside the scope of this entry.\\n\\n\\n== Overview and background ==\\n\\nInstant messaging technology is a type of online chat that offers real-time text transmission over the Internet.', 'stream': False, 'options': {'temperature': 0.5, 'max_tokens': 700, 'top_p': 0.85, 'top_k': 50, 'repetition_penalty': 1.15, 'num_ctx': 9096}}\n",
      "Time taken: 38.780598402023315s\n",
      "Based on the provided data from Wikipedia, I've extracted key requirements for an AI-powered Study Companion Discord Bot:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1.\n",
      "**User Experience:** The bot should provide an intuitive and user-friendly interface to facilitate seamless communication between users and the study companion.\n",
      "2.\n",
      "**Real-time Text Transmission:** The bot should enable real-time text transmission, allowing users to engage in instant conversations and receive immediate responses.\n",
      "3.\n",
      "**Personalization:** The bot should be able to personalize its interactions with each user, taking into account their individual needs and preferences.\n",
      "\n",
      "**Technical Specifications:**\n",
      "\n",
      "1.\n",
      "**Programming Language:** The bot's backend should be built using a suitable programming language that can handle real-time text transmission, such as Python or JavaScript.\n",
      "2.\n",
      "**Database Management:** A robust database management system should be implemented to store user data, study materials, and chat history.\n",
      "3.\n",
      "**Natural Language Processing (NLP):** The bot should utilize NLP techniques to understand and analyze user inputs, enabling it to provide accurate and relevant responses.\n",
      "\n",
      "**Best Practices:**\n",
      "\n",
      "1.\n",
      "**Security:** Ensure the bot's security measures are in place to protect user data and prevent unauthorized access.\n",
      "2.\n",
      "**Scalability:** Design the bot to scale with increasing user traffic, ensuring a seamless experience for all users.\n",
      "3.\n",
      "**Continuous Learning:** Implement a system that allows the bot to learn from user interactions and improve its responses over time.\n",
      "\n",
      "**Additional Requirements:**\n",
      "\n",
      "1.\n",
      "**Integration with Study Materials:** The bot should be able to integrate with various study materials, such as textbooks, notes, and online resources, to provide users with relevant information.\n",
      "2.\n",
      "**Gamification and Motivation:** Incorporate features that encourage users to stay motivated and engaged, such as rewards, challenges, or leaderboards.\n",
      "\n",
      "By incorporating these key features, technical specifications, and best practices, the AI-powered Study Companion Discord Bot can provide a comprehensive and effective study experience for its users..\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import wikipedia\n",
    "from functools import lru_cache\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "# Function to retrieve data from Wikipedia with multiple summaries\n",
    "def retrieve_wikipedia_data(query):\n",
    "    try:\n",
    "        results = wikipedia.search(query)  # Get relevant article titles\n",
    "        summaries = []\n",
    "        for title in results[:3]:  # Limit to top 3 results\n",
    "            try:\n",
    "                summary = wikipedia.summary(title, sentences=5)\n",
    "                summaries.append(f\"**{title}**: {summary}\")\n",
    "            except Exception:\n",
    "                continue  # Skip problematic pages\n",
    "        return \"\\n\\n\".join(summaries) if summaries else \"No relevant Wikipedia data found.\"\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Multiple possible matches found: {e.options}. Please refine your query.\"\n",
    "    except wikipedia.exceptions.HTTPError:\n",
    "        return \"Sorry, there was an issue accessing Wikipedia.\"\n",
    "    except wikipedia.exceptions.RedirectError:\n",
    "        return \"Sorry, the page is a redirect. Try a more specific query.\"\n",
    "    except wikipedia.exceptions.Timeout:\n",
    "        return \"The request timed out. Please try again later.\"\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {str(e)}\"\n",
    "\n",
    "# Define the inbound prompt for requirement analysis\n",
    "RAG_SHOT = \"\"\"You are a highly capable AI assistant specialized in automating requirement analysis.  \n",
    "Your task is to extract and analyze requirements for an AI-powered Study Companion Discord Bot by retrieving relevant data from Wikipedia and generating structured, insightful answers.\n",
    "\n",
    "Please ensure your answers clearly outline key features, technical specifications, and best practices based on the retrieved data.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = RAG_SHOT + \"\\nAnalyze the following requirement: {user_query}\"\n",
    "\n",
    "# Cache frequent Wikipedia data retrievals to improve performance\n",
    "@lru_cache(maxsize=50)\n",
    "def get_retrieved_data(query):\n",
    "    return retrieve_wikipedia_data(query)\n",
    "\n",
    "# Function to format the response with new lines between sentences\n",
    "def format_response(response):\n",
    "    sentences = response.split('. ')\n",
    "    formatted_response = '\\n'.join([sentence.strip() + '.' for sentence in sentences if sentence])\n",
    "    return formatted_response\n",
    "\n",
    "def generate_requirement_analysis(user_query):\n",
    "    retrieved_wiki = get_retrieved_data(user_query)\n",
    "    \n",
    "    # Incorporate the retrieved data into the prompt\n",
    "    prompt = PROMPT.format(user_query=user_query) + \"\\n\\n\" + retrieved_wiki\n",
    "    \n",
    "    # Configure payload for the AI model request\n",
    "    payload = create_payload(\n",
    "        target=\"ollama\",                \n",
    "        model=\"llama3.2:latest\",        \n",
    "        prompt=prompt,\n",
    "        temperature=0.5,       # More deterministic output\n",
    "        max_tokens=700,        # More detailed responses for requirement analysis\n",
    "        top_p=0.85,            # More refined token selection\n",
    "        top_k=50,              # Restrict token selection further\n",
    "        repetition_penalty=1.15,  # Penalize repetitions\n",
    "        num_ctx=9096,          # Context window size\n",
    "    )\n",
    "    \n",
    "    # Send the request to the model\n",
    "    start_time = time.time()\n",
    "    response = model_req(payload=payload)\n",
    "    end_time = time.time()\n",
    "    print(f'Time taken: {end_time - start_time}s')\n",
    "    \n",
    "    # Extract response text (assuming response is a tuple with the second element as the text)\n",
    "    response_text = response[1] if isinstance(response, tuple) else response\n",
    "    \n",
    "    # Format the response for readability\n",
    "    formatted_response = format_response(response_text)\n",
    "    return formatted_response\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"What are the key requirements for an AI-powered Study Companion Discord Bot?\"\n",
    "    response = generate_requirement_analysis(user_query)\n",
    "    print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
